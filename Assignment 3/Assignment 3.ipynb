{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Libraries import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skmultiflow.trees import HoeffdingTree\n",
    "from skmultiflow.evaluation import EvaluatePrequential\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.- Data reading, preprocessing and parameters setting\n",
    "\n",
    "data = pd.read_csv(\"cs-training.csv\") # Give me some credit data, drop na for easier use\n",
    "# data = pd.read_csv(\"heart.csv\", sep = \";\", decimal = \",\") # Give me some credit data, drop na for easier use\n",
    "data = data.dropna()\n",
    "\n",
    "L = 2                                 # Number of instances\n",
    "I = 750                              # Size of the data block\n",
    "D = 20                                # Number of dynamic classifiers\n",
    "eps = 0.25                            # Instance selection ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120269, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "0           1                 1                              0.766127   45   \n",
       "1           2                 0                              0.957151   40   \n",
       "2           3                 0                              0.658180   38   \n",
       "3           4                 0                              0.233810   30   \n",
       "4           5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                     2   0.802982         9120.0   \n",
       "1                                     0   0.121876         2600.0   \n",
       "2                                     1   0.085113         3042.0   \n",
       "3                                     0   0.036050         3300.0   \n",
       "4                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                               13                        0   \n",
       "1                                4                        0   \n",
       "2                                2                        1   \n",
       "3                                5                        0   \n",
       "4                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                             6                                     0   \n",
       "1                             0                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define 5 functions, most of them as detailed in the paper https://ieeexplore.ieee.org/abstract/document/8706959:\n",
    "\n",
    " - **Ensemble**: Main function, as detailed in the paper\n",
    " - **CreateNewBaseClassfier**: As detailed in the paper\n",
    " - **ReinformentAdjustment**: As detailed in the paper\n",
    " - **TrainOnInstance**: As detailed in the paper\n",
    " - **predict**: Used for prediction of new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(S,L,I,D,eps):\n",
    "    \n",
    "    # 1.- INITIALIZATION\n",
    "    \n",
    "    labels = np.asarray(S.iloc[:,1])         # Labels    \n",
    "    S = np.asarray(S.iloc[:,2:S.shape[1]])   # Data\n",
    "\n",
    "#     S = np.asarray(S.iloc[:,0:data.shape[1]-1])\n",
    "#     labels = np.asarray(data.iloc[:,-1]) \n",
    "    B = []                                      # Circular array\n",
    "    U = [[] for i in range(0,L)]                # Resampling buffer\n",
    "    DCIR = [1/L for i in range(0,L)]            # Class imbalance ratio\n",
    "    C = []                                      # Classifiers vector\n",
    "    H = [[0 for i in range(0,D)] for i in range(0,L)]  # NÂº of instances of different classes\n",
    "    ws = 0.5                                    # Static weight\n",
    "    wd = [1/D for i in range(0,D-1)]            # Dynamic weights\n",
    "\n",
    "    p = 0                                       # Processed instances counter\n",
    "    i = 0                                       # Position of circular array\n",
    "    k = 0                                       # Indicator of dynamic classifiers\n",
    "    kc = 0                                      # Circular indicator of dynamic classifiers\n",
    "    \n",
    "    is_ok = 0\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    pre = 0\n",
    "    rec = 0\n",
    "    pre_pre = 0\n",
    "    pre_rec = 0\n",
    "    \n",
    "    pre_tp = 0\n",
    "    pre_fp = 0\n",
    "    pre_fn = 0\n",
    "    \n",
    "    f1_score = []\n",
    "#     acc_pre = []\n",
    "#     auc_pre = []\n",
    "#     acc_pre_past = []\n",
    "#     auc_pre_past = []\n",
    "#     acc_post = []\n",
    "#     auc_post = []\n",
    "#     acc_post_past = []\n",
    "#     auc_post_past = []\n",
    "    # 2.- PROCESS\n",
    "    \n",
    "    for j in range(0, len(S)):\n",
    "        \n",
    "        xnew = S[j]\n",
    "        p = p + 1\n",
    "        if (p%(I*D) == 0):\n",
    "            print(\"\")\n",
    "            print(\"Instances through stream: \", p)\n",
    "            print(\"Acc overall: \", is_ok/(j-I))\n",
    "            print(\"Micro-F1 score evaluating model at every new point and calculated every \", I, \" examples\")\n",
    "            print(\"F1 score: \", f1_score[-1])            \n",
    "#             print(\"Calculated for \", I,\" next instances every time a new classifier is introduced (Then avg)\")\n",
    "#             print(\"Acc pre new model: \", np.mean(acc_pre))\n",
    "#             print(\"Auc pre new model: \", np.mean(auc_pre))\n",
    "#             print(\"Acc post new model: \", np.mean(acc_post))\n",
    "#             print(\"Auc post new model: \", np.mean(auc_post))\n",
    "#             print(\"Acc pre new model PAST: \", np.mean(acc_pre_past))\n",
    "#             print(\"Auc pre new model PAST: \", np.mean(auc_pre_past))\n",
    "#             print(\"Acc post new model PAST: \", np.mean(acc_post_past))\n",
    "#             print(\"Auc post new model PAST: \", np.mean(auc_post_past))\n",
    "            print(\"\")\n",
    "        \n",
    "        # 2.1.- FIRST INSTANCES\n",
    "        if (p < I):\n",
    "            B.append(xnew)\n",
    "        elif (p == I):\n",
    "            B.append(xnew)\n",
    "            [Cnew, H, U, ws, wd] = CreateNewBaseClassfier(eps, B, U, I, L, D, C, H, wd, ws, k, kc, DCIR, labels)\n",
    "            C.append(Cnew)\n",
    "            k = 1\n",
    "            kc = 1\n",
    "        \n",
    "        # 2.2.- MIDDLE INSTANCES\n",
    "        else:\n",
    "            #Evaluating            \n",
    "            sol = predict(S[j,:], C, ws, wd)[0]\n",
    "            \n",
    "            if sol == labels[j]:\n",
    "                is_ok += 1\n",
    "                if labels[j] == 1:\n",
    "                    tp += 1\n",
    "            elif sol != labels[j] and labels[j] == 1:\n",
    "                fn += 1\n",
    "            elif sol != labels[j] and labels[j] == 0:\n",
    "                fp += 1\n",
    "                \n",
    "            \n",
    "\n",
    "            i = (p-1)%I\n",
    "            \n",
    "            [B, C, ws, wd] = TrainOnInstance(xnew, i, L, D, B, C, wd, ws, DCIR[labels[p-I-1]], labels[p-I-1])\n",
    "            i = (i + 1)%I\n",
    "            if (i == 0):\n",
    "                k = k + 1\n",
    "                kc = k%D\n",
    "                \n",
    "                pre_tp = pre_tp + tp\n",
    "                pre_fp = pre_fp + fp\n",
    "                pre_fn = pre_fn + fn\n",
    "                \n",
    "                \n",
    "                if (pre_tp + pre_fp == 0) and (pre_tp + pre_fn == 0):\n",
    "                    f1_score.append(\"All cases true negatives so far\")\n",
    "                elif (pre_tp + pre_fp == 0):\n",
    "                    f1_score.append(\"No true positives neither false positives so far\")\n",
    "                elif (pre_tp + pre_fn == 0):\n",
    "                    f1_score.append(\"No true positives neither false negatives so far\")\n",
    "                else:\n",
    "                    pre = (pre_tp)/(pre_tp + pre_fp)\n",
    "                    rec = (pre_tp)/(pre_tp + pre_fn)\n",
    "                    \n",
    "                    f1_score.append((2 * pre * rec)/(pre + rec))\n",
    "\n",
    "                tp = 0\n",
    "                fp = 0\n",
    "                fn = 0\n",
    "\n",
    "#                 sol = predict(S[j:j+I,:], C, ws, wd)\n",
    "#                 fpr, tpr, thresholds = metrics.roc_curve(labels[j:j+I], sol)\n",
    "#                 auc_pre.append(metrics.auc(fpr, tpr))\n",
    "#                 acc_pre.append(np.sum(np.equal(sol, labels[j:j+I]))/I)\n",
    "                \n",
    "#                 sol = predict(S[j-I:j,:], C, ws, wd)\n",
    "#                 fpr, tpr, thresholds = metrics.roc_curve(labels[j-I:j], sol)\n",
    "#                 auc_pre_past.append(metrics.auc(fpr, tpr))\n",
    "#                 acc_pre_past.append(np.sum(np.equal(sol, labels[j-I:j]))/I)\n",
    "                \n",
    "                [Ck, H, U, ws, wd] = CreateNewBaseClassfier(eps, B, U, I, L, D, C, H, wd, ws, k, kc, DCIR, labels)\n",
    "                    \n",
    "#                 sol = predict(S[j:j+I,:], C, ws, wd)\n",
    "#                 fpr, tpr, thresholds = metrics.roc_curve(labels[j:j+I], sol)\n",
    "#                 auc_post.append(metrics.auc(fpr, tpr))\n",
    "#                 acc_post.append(np.sum(np.equal(sol, labels[j:j+I]))/I)\n",
    "                \n",
    "#                 sol = predict(S[j-I:j,:], C, ws, wd)\n",
    "#                 fpr, tpr, thresholds = metrics.roc_curve(labels[j-I:j], sol)\n",
    "#                 auc_post_past.append(metrics.auc(fpr, tpr))\n",
    "#                 acc_post_past.append(np.sum(np.equal(sol, labels[j-I:j]))/I)\n",
    "                \n",
    "                if k > D:\n",
    "\n",
    "                    C[0:len(C)-1] = C[1::]\n",
    "                    C[-1] = Ck\n",
    "                    \n",
    "                    ws = 1/2\n",
    "                    wd[0:D-2] = list(map(lambda x: x * (1-1/D), wd[1:D-1]))\n",
    "                    wd[-1] = 1/D\n",
    "                else:\n",
    "                    C.append(Ck)\n",
    "                    ws = 1/2\n",
    "                    wd[0:k-2] = list(map(lambda x: x * (1-1/D), wd[0:k-2]))\n",
    "                    wd[0] = 1/D\n",
    "\n",
    "                if k < D:\n",
    "                    l = k\n",
    "                else:\n",
    "                    l = D\n",
    "                temp = [np.asarray(H[i][1:l+1]) * np.asarray(wd[0:l]) for i in range(0,L)]\n",
    "                for i in range(0,L):\n",
    "                    DCIR[i] = np.sum(temp[i])/np.sum(temp)\n",
    "                    \n",
    "    # 2.3.- FINAL INSTANCES\n",
    "    for j in range(0,I-1):\n",
    "        xnew = B[j]\n",
    "        [B, C, ws, wd] = TrainOnInstance(xnew, i, L, D, B, C, wd, ws, DCIR[labels[j-I]], labels[len(labels)-I+j])\n",
    "    \n",
    "    print(\"------------END------------\")\n",
    "    print(\"Instances through stream: \", p)\n",
    "    print(\"Acc overall: \", is_ok/(len(data)-I))\n",
    "    print(\"Micro-F1 score evaluating model at every new point and calculated every \", I, \" examples\")\n",
    "    print(\"F1 score: \", f1_score[-1])  \n",
    "    plt.plot(f1_score)\n",
    "#     print(\"Calculated for \", I,\" next instances every time a new classifier is introduced (Then avg)\")\n",
    "#     print(\"Acc pre new model: \", np.mean(acc_pre))\n",
    "#     print(\"Auc pre new model: \", np.mean(auc_pre))\n",
    "#     print(\"Acc post new model: \", np.mean(acc_post))\n",
    "#     print(\"Auc post new model: \", np.mean(auc_post))\n",
    "#     print(\"Acc pre new model PAST: \", np.mean(acc_pre_past))\n",
    "#     print(\"Auc pre new model PAST: \", np.mean(auc_pre_past))\n",
    "#     print(\"Acc post new model PAST: \", np.mean(acc_post_past))\n",
    "#     print(\"Auc post new model PAST: \", np.mean(auc_post_past))\n",
    "    print(\"\")\n",
    "    return [C,ws,wd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateNewBaseClassfier(eps, B, U, I, L, D, C, H, wd, ws, k, kc, DCIR, labels):\n",
    "    \n",
    "    # 1.- Select top eps*I instances\n",
    "    Rn = B[0:int(I*eps)]\n",
    "    Rlabels = labels[0:int(I*eps)]\n",
    "    \n",
    "    # 2.- In case is not the first classifier, perform weight adjustment\n",
    "    if k != 0:\n",
    "        for i in range(0, len(Rn)):\n",
    "            [ws,wd] = ReinformentAdjustment(np.asarray([Rn[i]]), L, D, C, wd, ws, DCIR[Rlabels[i]],Rlabels[i])\n",
    "    \n",
    "    # 3.- Calculate instance numbers\n",
    "    for i in range(0,L):\n",
    "        H[i][kc] = len(np.where(Rlabels[0:int(I*eps)]==i)[0])\n",
    "    \n",
    "    # 4.- Create new classifier\n",
    "    Cnew = HoeffdingTree()\n",
    "    \n",
    "    # 5.- In case is not the first classifier, train in previous instances for balance\n",
    "    if k != 0:\n",
    "        if (H[0][kc] < int(I*eps/L)) and (len(U[0])>0):\n",
    "            U0 = np.array(U[0])\n",
    "            if len(U[0]) >= (int(I*eps/L) - H[0][kc]):\n",
    "                Cnew.fit(U0[-(int(I*eps/L) - H[1][kc]):], np.asarray([0 for i in range(0, (int(I*eps/L) - H[0][kc]))]))\n",
    "            else:\n",
    "                Cnew.fit(U0, np.asarray([0 for i in range(0, len(U[0]))]))\n",
    "        elif (H[1][kc] < int(I*eps/L)) and (len(U[1])>0):\n",
    "            U1 = np.array(U[1])\n",
    "            \n",
    "            if len(U[1]) >= (int(I*eps/L) - H[1][kc]):\n",
    "                Cnew.fit(U1[-(int(I*eps/L) - H[1][kc]):], np.asarray([1 for i in range(0, (int(I*eps/L) - H[1][kc]))]))\n",
    "            else:\n",
    "                Cnew.fit(U1, np.asarray([1 for i in range(0, len(U[1]))]))\n",
    "        Cnew.partial_fit(Rn,Rlabels)\n",
    "            \n",
    "    else:\n",
    "        # 6.- Train the new classifier\n",
    "#         print(Rn)\n",
    "        Cnew.fit(np.array(Rn), np.array(Rlabels))\n",
    "    \n",
    "    # 7.- Adapt the resampling buffer\n",
    "    for i in range(0,len(Rn)):\n",
    "        if Rlabels[i] == 0:\n",
    "            U[0].append(Rn[i])\n",
    "            if len(U[0])> int(I*eps/L):\n",
    "                U[0].pop()\n",
    "        else:            \n",
    "            U[1].append(Rn[i])\n",
    "            if len(U[1])> int(I*eps/L):\n",
    "                U[1].pop()\n",
    "    \n",
    "    return [Cnew, H, U, ws, wd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  ReinformentAdjustment(x, L, D, C, wd, ws, DCIR, label):\n",
    "    if (DCIR < 1/L):\n",
    "        for d in range(1,len(C)-1):\n",
    "            if (C[d].predict(x)[0] == label):\n",
    "#                 print(\"HEY!!\")\n",
    "#                 print(label)\n",
    "                wd[d] = wd[d]*(1+1/D)\n",
    "#                 print(wd)\n",
    "            else:\n",
    "                wd[d] = wd[d]*(1-1/D)\n",
    "        if (C[0].predict(x)[0] == label):\n",
    "#             print(\"HEY!!\")\n",
    "            ws = ws*(1+1/D)\n",
    "        else:\n",
    "            ws = ws*(1-1/D)   \n",
    "    return [ws,wd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainOnInstance(xnew, i, L, D, B, C, wd, ws, DCIR, label):\n",
    "    x = np.asarray([B[i]])\n",
    "    [ws, wd] = ReinformentAdjustment(x, L, D, C, wd, ws, DCIR, label)\n",
    "    for j in range(0,len(C)):\n",
    "        if label == 1:\n",
    "            C[j].partial_fit(x, [label])\n",
    "        elif (label == 0) and (np.random.rand(1)<0.15):\n",
    "            C[j].partial_fit(x, [label])\n",
    "    B[i] = xnew\n",
    "    return [B, C, ws, wd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, C, ws, wd):\n",
    "    if len(data.shape) < 2:\n",
    "        data = np.asarray(data).reshape((data.shape[0], 1))\n",
    "    else:\n",
    "        data = np.asarray(data)\n",
    "    pred = C[0].predict(data)*ws\n",
    "#     print(wd)\n",
    "    for i in range(1, len(C)-1):\n",
    "#         print(\"Classifier: \", i)\n",
    "    \n",
    "        pred = pred + C[i].predict(data)*wd[i-1]\n",
    "    for i in range(0, len(pred)):\n",
    "        if pred[i] >= 0.5:\n",
    "            pred[i] = 1\n",
    "        else:\n",
    "            pred[i] = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy F1 (All 0):  0.9640065293887097\n",
      "Dummy F1 (All random):  0.12079144259995325\n",
      "Dummy Acc (All 0):  0.930514097564626\n",
      "Dummy Acc (All random):  0.4997380871213696\n",
      "\n",
      "Instances through stream:  15000\n",
      "Acc overall:  0.9299599971927854\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.01869158878504673\n",
      "\n",
      "\n",
      "Instances through stream:  30000\n",
      "Acc overall:  0.769735717460426\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.12263876780005814\n",
      "\n",
      "\n",
      "Instances through stream:  45000\n",
      "Acc overall:  0.6189970394811182\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13978714695047073\n",
      "\n",
      "\n",
      "Instances through stream:  60000\n",
      "Acc overall:  0.5839423450184813\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13682913953897588\n",
      "\n",
      "\n",
      "Instances through stream:  75000\n",
      "Acc overall:  0.5858664763161794\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13477853758193115\n",
      "\n",
      "\n",
      "Instances through stream:  90000\n",
      "Acc overall:  0.5817544174164416\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13413245986944503\n",
      "\n",
      "\n",
      "Instances through stream:  105000\n",
      "Acc overall:  0.5727345106427879\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13615188882364457\n",
      "\n",
      "\n",
      "Instances through stream:  120000\n",
      "Acc overall:  0.5942188194450267\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.13494841061163798\n",
      "\n",
      "------------END------------\n",
      "Instances through stream:  120269\n",
      "Acc overall:  0.5930437838335327\n",
      "Micro-F1 score evaluating model at every new point and calculated every  750  examples\n",
      "F1 score:  0.1350897261743047\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-43d883366e65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total time: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-742e4689cef3>\u001b[0m in \u001b[0;36mensemble\u001b[1;34m(S, L, I, D, eps)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Micro-F1 score evaluating model at every new point and calculated every \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" examples\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;31m#     print(\"Calculated for \", I,\" next instances every time a new classifier is introduced (Then avg)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;31m#     print(\"Acc pre new model: \", np.mean(acc_pre))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 4.- Test and metrics\n",
    "start_time = time.time()\n",
    "rand = np.random.randint(0,2, size = len(np.asarray(data.iloc[:,1])))\n",
    "dummy_tp_r = np.logical_and((np.asarray(data.iloc[:,1])   == rand), (np.asarray(data.iloc[:,1]) == 1))\n",
    "dummy_fp_r = np.logical_and((np.asarray(data.iloc[:,1])   != rand), (np.asarray(data.iloc[:,1]) == 1))\n",
    "dummy_fn_r = np.logical_and((np.asarray(data.iloc[:,1])   != rand),(np.asarray(data.iloc[:,1]) == 0))\n",
    "dummy_pre_r = (np.sum(dummy_tp_r)/(np.sum(dummy_tp_r) + np.sum(dummy_fp_r)))\n",
    "dummy_rec_r = (np.sum(dummy_tp_r))/(np.sum(dummy_tp_r) + np.sum(dummy_fn_r))\n",
    "dummy_f1_r = (2 * dummy_pre_r * dummy_rec_r)/(dummy_pre_r + dummy_rec_r)\n",
    "\n",
    "dummy_acc_r = np.sum(np.asarray(data.iloc[:,1]) == rand)/len(np.asarray(data.iloc[:,1]))\n",
    "dummy_acc = np.sum(np.asarray(data.iloc[:,1]) == 0)/len(np.asarray(data.iloc[:,1]))\n",
    "\n",
    "dummy_tp = np.asarray(data.iloc[:,1])   == 0\n",
    "dummy_fp = np.asarray(data.iloc[:,1])   == 2\n",
    "dummy_fn = np.asarray(data.iloc[:,1])   == 1\n",
    "dummy_pre = (np.sum(dummy_tp)/(np.sum(dummy_tp) + np.sum(dummy_fp)))\n",
    "dummy_rec = (np.sum(dummy_tp))/(np.sum(dummy_tp) + np.sum(dummy_fn))\n",
    "dummy_f1 = (2 * dummy_pre * dummy_rec)/(dummy_pre + dummy_rec)\n",
    "print(\"Dummy F1 (All 0): \", dummy_f1)\n",
    "print(\"Dummy F1 (All random): \", dummy_f1_r)\n",
    "print(\"Dummy Acc (All 0): \", dummy_acc)\n",
    "print(\"Dummy Acc (All random): \", dummy_acc_r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ret = ensemble(data,L,I,D,eps)\n",
    "end_time = time.time()\n",
    "print(\"Total time: \", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
